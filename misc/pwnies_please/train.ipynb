{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import time\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "data_dir = 'horse2zebra'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=4)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, Callable, Tuple\n",
    "from functools import reduce\n",
    "from collections import deque\n",
    "from typing import Union, Tuple\n",
    "from torch.nn import Module\n",
    "\n",
    "def _iterative_gradient(model: Module,\n",
    "                        x: torch.Tensor,\n",
    "                        y: torch.Tensor,\n",
    "                        loss_fn: Callable,\n",
    "                        k: int,\n",
    "                        step: float,\n",
    "                        eps: float,\n",
    "                        norm: Union[str, float],\n",
    "                        step_norm: Union[str, float],\n",
    "                        y_target: torch.Tensor = None,\n",
    "                        random: bool = False) -> torch.Tensor:\n",
    "  \n",
    "    x_adv = x.clone().detach().requires_grad_(True).to(x.device)\n",
    "    targeted = y_target is not None\n",
    "\n",
    "    if random:\n",
    "        x_adv = random_perturbation(x_adv, norm, eps)\n",
    "\n",
    "    for i in range(k):\n",
    "        _x_adv = x_adv.clone().detach().requires_grad_(True)\n",
    "\n",
    "        prediction = model(_x_adv)\n",
    "        loss = loss_fn(prediction, y_target if targeted else y)\n",
    "        loss.backward()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            if step_norm == 'inf':\n",
    "                gradients = _x_adv.grad.sign()*step\n",
    "            else:\n",
    "                # .view() assumes batched image data as 4D tensor\n",
    "                gradients = _x_adv.grad * step / _x_adv.grad.view(_x_adv.shape[0], -1).norm(step_norm, dim=-1)\\\n",
    "                    .view(-1, 1, 1, 1)\n",
    "\n",
    "            if targeted:\n",
    "                # Targeted: Gradient descent with on the loss of the (incorrect) target label\n",
    "                # w.r.t. the model parameters\n",
    "                x_adv -= gradients\n",
    "            else:\n",
    "                # Untargeted: Gradient ascent on the loss of the correct label w.r.t.\n",
    "                # the model parameters\n",
    "                x_adv += gradients\n",
    "\n",
    "\n",
    "        # Project back into l_norm ball and correct range\n",
    "        x_adv = project(x, x_adv, norm, eps)\n",
    "\n",
    "    return x_adv.detach()\n",
    "\n",
    "def pgd(model: Module,\n",
    "        x: torch.Tensor,\n",
    "        y: torch.Tensor,\n",
    "        loss_fn: Callable,\n",
    "        k: int,\n",
    "        step: float,\n",
    "        eps: float,\n",
    "        norm: Union[str, float],\n",
    "        y_target: torch.Tensor = None,\n",
    "        random: bool = False) -> torch.Tensor:\n",
    "   \n",
    "    return _iterative_gradient(model=model, x=x, y=y, loss_fn=loss_fn, k=k, eps=eps, norm=norm, step=step, step_norm=2,\n",
    "                               y_target=y_target, random=random)\n",
    "\n",
    "\n",
    "def project(x: torch.Tensor, x_adv: torch.Tensor, norm: Union[str, int], eps: float) -> torch.Tensor:\n",
    "    \n",
    "    if x.shape != x_adv.shape:\n",
    "        raise ValueError('Input Tensors must have the same shape')\n",
    "\n",
    "    if norm == 'inf':\n",
    "        # Workaround as PyTorch doesn't have elementwise clip\n",
    "        x_adv = torch.max(torch.min(x_adv, x + eps), x - eps)\n",
    "    else:\n",
    "        delta = x_adv - x\n",
    "\n",
    "        # Assume x and x_adv are batched tensors where the first dimension is\n",
    "        # a batch dimension\n",
    "        mask = delta.view(delta.shape[0], -1).norm(norm, dim=1) <= eps\n",
    "\n",
    "        scaling_factor = delta.view(delta.shape[0], -1).norm(norm, dim=1)\n",
    "        scaling_factor[mask] = eps\n",
    "\n",
    "        # .view() assumes batched images as a 4D Tensor\n",
    "        delta *= eps / scaling_factor.view(-1, 1, 1, 1)\n",
    "\n",
    "        x_adv = x + delta\n",
    "\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs, epsilon):\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            for i, (inputs, labels) in enumerate(dataloaders[phase]):\n",
    "#                 if (i%50==0):\n",
    "#                     print('Batch : {}'.format(i))\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                if (epsilon != 0):\n",
    "                    inputs = pgd(model, inputs, labels, criterion, k=10, step=0.1, eps=epsilon, norm=2)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "#                     print(inputs)\n",
    "                    outputs = model(inputs)\n",
    "                    preds = torch.argmax(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "     \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)      \n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            print('{} loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))            \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "            model_wts = copy.deepcopy(model.state_dict())\n",
    "        print()\n",
    "    print('Best val accuracy: {:4f}'.format(best_acc))\n",
    "    model.load_state_dict(model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=3e-5)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "train loss: 0.3077 Acc: 0.8613\n",
      "val loss: 0.0666 Acc: 0.9911\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "train loss: 0.2264 Acc: 0.9145\n",
      "val loss: 0.0429 Acc: 0.9931\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "train loss: 0.2248 Acc: 0.9260\n",
      "val loss: 0.0472 Acc: 0.9901\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "train loss: 0.1458 Acc: 0.9504\n",
      "val loss: 0.0508 Acc: 0.9901\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "train loss: 0.1294 Acc: 0.9518\n",
      "val loss: 0.0660 Acc: 0.9812\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "train loss: 0.1791 Acc: 0.9418\n",
      "val loss: 0.0251 Acc: 0.9921\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "train loss: 0.1451 Acc: 0.9547\n",
      "val loss: 0.0323 Acc: 0.9950\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "train loss: 0.1794 Acc: 0.9396\n",
      "val loss: 0.0245 Acc: 0.9960\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "train loss: 0.1496 Acc: 0.9540\n",
      "val loss: 0.0360 Acc: 0.9891\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "train loss: 0.1554 Acc: 0.9482\n",
      "val loss: 0.0283 Acc: 0.9941\n",
      "\n",
      "Best val accuracy: 0.996040\n",
      "Epoch 1/10\n",
      "----------\n",
      "train loss: 0.6818 Acc: 0.7692\n",
      "val loss: 0.1831 Acc: 0.9465\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "train loss: 0.4819 Acc: 0.8174\n",
      "val loss: 0.1472 Acc: 0.9545\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "train loss: 0.4568 Acc: 0.8124\n",
      "val loss: 0.2726 Acc: 0.8792\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "train loss: 0.4258 Acc: 0.8354\n",
      "val loss: 0.7258 Acc: 0.7099\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "train loss: 0.4159 Acc: 0.8411\n",
      "val loss: 0.1272 Acc: 0.9624\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "train loss: 0.3914 Acc: 0.8548\n",
      "val loss: 0.1626 Acc: 0.9545\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "train loss: 0.3709 Acc: 0.8512\n",
      "val loss: 1.2887 Acc: 0.6465\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "train loss: 0.4027 Acc: 0.8519\n",
      "val loss: 0.2625 Acc: 0.8941\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "train loss: 0.3321 Acc: 0.8670\n",
      "val loss: 0.0758 Acc: 0.9802\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "train loss: 0.3413 Acc: 0.8677\n",
      "val loss: 0.1178 Acc: 0.9703\n",
      "\n",
      "Best val accuracy: 0.980198\n"
     ]
    }
   ],
   "source": [
    "for i in [0, 3]:\n",
    "    model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, num_epochs=10, epsilon=i)\n",
    "    torch.save(model_ft.state_dict(), \"models/pwny_eps_\"+str(i)+\".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-5a18bc2a1607>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstratify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'new_data/data_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'new_data/label_train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'new_data/data_val'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mc:\\users\\anush\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    536\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m             \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.npy'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "# worklist: train test split to remake splits, then retrain\n",
    "data = np.load('train_final_data_1.npy')\n",
    "labels = np.load('train_final_label_1.npy')\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.30, random_state=42, stratify=labels)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=0.50, random_state=21, stratify = y_test)\n",
    "np.save(X_train, 'new_data/data_train')\n",
    "np.save(y_train, 'new_data/label_train')\n",
    "np.save(X_val, 'new_data/data_val')\n",
    "np.save(y_val, 'new_data/label_val')\n",
    "np.save(X_test, 'new_data/data_test')\n",
    "np.save(y_test, 'new_data/label_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
